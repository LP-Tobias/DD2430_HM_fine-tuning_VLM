{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "from src import util\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/hf/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\", \n",
    "                                  cache_dir=\"model\", local_files_only=True)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\", \n",
    "                                          cache_dir=\"model\", local_files_only=True)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 151277313\n"
     ]
    }
   ],
   "source": [
    "# number of parameters\n",
    "print(f\"Number of parameters: {model.num_parameters()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "articles = pd.read_csv(f\"{data_dir}/articles.csv\")\n",
    "# customers = pd.read_csv(f\"{data_dir}/customers.csv\")\n",
    "# transactions = pd.read_csv(f\"{data_dir}/transactions_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_id: 105542\n",
      "product_code: 47224\n",
      "prod_name: 45875\n",
      "product_type_no: 132\n",
      "product_type_name: 131\n",
      "product_group_name: 19\n",
      "graphical_appearance_no: 30\n",
      "graphical_appearance_name: 30\n",
      "colour_group_code: 50\n",
      "colour_group_name: 50\n",
      "perceived_colour_value_id: 8\n",
      "perceived_colour_value_name: 8\n",
      "perceived_colour_master_id: 20\n",
      "perceived_colour_master_name: 20\n",
      "department_no: 299\n",
      "department_name: 250\n",
      "index_code: 10\n",
      "index_name: 10\n",
      "index_group_no: 5\n",
      "index_group_name: 5\n",
      "section_no: 57\n",
      "section_name: 56\n",
      "garment_group_no: 21\n",
      "garment_group_name: 21\n",
      "detail_desc: 43405\n"
     ]
    }
   ],
   "source": [
    "# map from article_id to df index\n",
    "article_id_to_idx = {article_id: idx for idx, article_id in enumerate(articles[\"article_id\"])}\n",
    "\n",
    "# get all classes of the dataframe\n",
    "class_names = articles.columns.tolist()\n",
    "label_names = dict()\n",
    "for class_name in class_names:\n",
    "    label_names[class_name] = articles[class_name].unique()\n",
    "    print(f\"{class_name}: {len(label_names[class_name])}\")\n",
    "article_ids = label_names[\"article_id\"]\n",
    "selected_class_names = [\"product_group_name\", \"product_type_name\", \"graphical_appearance_name\", \"colour_group_name\", \"perceived_colour_value_name\", \"perceived_colour_master_name\", \"department_name\", \"index_name\", \"index_group_name\", \"section_name\", \"garment_group_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 105100\n"
     ]
    }
   ],
   "source": [
    "image_paths, labels = util.get_image_paths_and_labels_ordered(articles, data_dir)\n",
    "print(f\"Number of images: {len(image_paths)}\")\n",
    "\n",
    "# split 0.6/0.2/0.2\n",
    "# image_paths_train, image_paths_val, labels_train, labels_val = train_test_split(\n",
    "#     image_paths, labels, test_size=0.2, random_state=42)\n",
    "# image_paths_train, image_paths_test, labels_train, labels_test = train_test_split(\n",
    "#     image_paths_train, labels_train, test_size=0.25, random_state=42)\n",
    "\n",
    "dataset = util.ImageDataset(image_paths=image_paths, labels=labels, processor=processor)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class name: product_group_name\tTrue label: Garment Upper body\n",
      "Garment Upper body:\t0.4556\n",
      "Nightwear:\t0.1890\n",
      "Garment Lower body:\t0.1040\n",
      "Garment Full body:\t0.0965\n",
      "Underwear/nightwear:\t0.0912\n",
      "\n",
      "Class name: product_type_name\tTrue label: Vest top\n",
      "Vest top:\t0.8381\n",
      "Swimwear top:\t0.0419\n",
      "Jumpsuit/Playsuit:\t0.0313\n",
      "Bodysuit:\t0.0281\n",
      "Pyjama jumpsuit/playsuit:\t0.0146\n",
      "\n",
      "Class name: graphical_appearance_name\tTrue label: Solid\n",
      "Chambray:\t0.1865\n",
      "Other pattern:\t0.1409\n",
      "Slub:\t0.1329\n",
      "Melange:\t0.1112\n",
      "Colour blocking:\t0.0713\n",
      "\n",
      "Class name: colour_group_name\tTrue label: Black\n",
      "Dark Green:\t0.1954\n",
      "Black:\t0.1702\n",
      "Dark Blue:\t0.0994\n",
      "Dark Grey:\t0.0950\n",
      "Dark Beige:\t0.0634\n",
      "\n",
      "Class name: perceived_colour_value_name\tTrue label: Dark\n",
      "Dark:\t0.4158\n",
      "Medium:\t0.3423\n",
      "Medium Dusty:\t0.1090\n",
      "Bright:\t0.0814\n",
      "Undefined:\t0.0384\n",
      "\n",
      "Class name: perceived_colour_master_name\tTrue label: Black\n",
      "Black:\t0.6113\n",
      "Khaki green:\t0.0914\n",
      "Grey:\t0.0558\n",
      "White:\t0.0548\n",
      "Brown:\t0.0445\n",
      "\n",
      "Class name: department_name\tTrue label: Jersey Basic\n",
      "Light Basic Jersey:\t0.1492\n",
      "Jersey Basic:\t0.1207\n",
      "Kids Girl Jersey Basic:\t0.1074\n",
      "Men Sport Tops:\t0.0982\n",
      "Young Girl Jersey Basic:\t0.0967\n",
      "\n",
      "Class name: index_name\tTrue label: Ladieswear\n",
      "Ladieswear:\t0.9448\n",
      "Children Sizes 134-170:\t0.0381\n",
      "Children Sizes 92-140:\t0.0048\n",
      "Children Accessories, Swimwear:\t0.0045\n",
      "Ladies Accessories:\t0.0037\n",
      "\n",
      "Class name: index_group_name\tTrue label: Ladieswear\n",
      "Ladieswear:\t0.9976\n",
      "Menswear:\t0.0013\n",
      "Sport:\t0.0008\n",
      "Divided:\t0.0003\n",
      "Baby/Children:\t0.0000\n",
      "\n",
      "Class name: section_name\tTrue label: Womens Everyday Basics\n",
      "Ladies H&M Sport:\t0.8255\n",
      "Men H&M Sport:\t0.0834\n",
      "Womens Swimwear, beachwear:\t0.0207\n",
      "Womens Everyday Basics:\t0.0172\n",
      "Womens Trend:\t0.0109\n",
      "\n",
      "Class name: garment_group_name\tTrue label: Jersey Basic\n",
      "Jersey Basic:\t0.7929\n",
      "Under-, Nightwear:\t0.0836\n",
      "Dresses Ladies:\t0.0591\n",
      "Swimwear:\t0.0201\n",
      "Jersey Fancy:\t0.0151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the first batch\n",
    "images, image_ids = next(iter(dataloader))\n",
    "\n",
    "for class_name in selected_class_names:\n",
    "    label_name = label_names[class_name]\n",
    "    text_inputs = processor(text=[f\"A photo of a {label}\" for label in label_name], return_tensors=\"pt\", padding=True)\n",
    "    text_inputs = text_inputs.to(device)\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**text_inputs, pixel_values=images)\n",
    "\n",
    "    logits_per_image = outputs.logits_per_image\n",
    "    probs = logits_per_image.softmax(dim=1)\n",
    "\n",
    "    probs = probs.to(\"cpu\")\n",
    "\n",
    "    values, indices = torch.topk(probs, k=5, dim=1)\n",
    "\n",
    "    # Only print the prediction for the first image\n",
    "    true_label = articles.loc[article_id_to_idx[image_ids[0].item()], class_name]\n",
    "    print(f\"Class name: {class_name}\\tTrue label: {true_label}\")\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        print(f\"{label_name[idx.item()]}:\\t{values[0][i].item():.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 822/822 [1:21:18<00:00,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_name='product_group_name'\n",
      "Top-1 accuracy: 0.33465271170313987\n",
      "Top-5 accuracy: 0.9118173168411037\n",
      "\n",
      "class_name='product_type_name'\n",
      "Top-1 accuracy: 0.3812369172216936\n",
      "Top-5 accuracy: 0.7733396764985728\n",
      "\n",
      "class_name='graphical_appearance_name'\n",
      "Top-1 accuracy: 0.07270218839200761\n",
      "Top-5 accuracy: 0.368116079923882\n",
      "\n",
      "class_name='colour_group_name'\n",
      "Top-1 accuracy: 0.2691341579448145\n",
      "Top-5 accuracy: 0.7252045670789724\n",
      "\n",
      "class_name='perceived_colour_value_name'\n",
      "Top-1 accuracy: 0.14960989533777355\n",
      "Top-5 accuracy: 0.6665271170313987\n",
      "\n",
      "class_name='perceived_colour_master_name'\n",
      "Top-1 accuracy: 0.5999048525214081\n",
      "Top-5 accuracy: 0.8928924833491912\n",
      "\n",
      "class_name='department_name'\n",
      "Top-1 accuracy: 0.08846812559467174\n",
      "Top-5 accuracy: 0.3135775451950523\n",
      "\n",
      "class_name='index_name'\n",
      "Top-1 accuracy: 0.3254900095147479\n",
      "Top-5 accuracy: 0.7511132254995243\n",
      "\n",
      "class_name='index_group_name'\n",
      "Top-1 accuracy: 0.41586108468125593\n",
      "Top-5 accuracy: 1.0\n",
      "\n",
      "class_name='section_name'\n",
      "Top-1 accuracy: 0.14439581351094197\n",
      "Top-5 accuracy: 0.3370884871550904\n",
      "\n",
      "class_name='garment_group_name'\n",
      "Top-1 accuracy: 0.38303520456707896\n",
      "Top-5 accuracy: 0.7554234062797336\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bs = 128\n",
    "shuffle = False\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=shuffle)\n",
    "\n",
    "top1_correct = {class_name: 0 for class_name in selected_class_names}\n",
    "top5_correct = {class_name: 0 for class_name in selected_class_names}\n",
    "\n",
    "date = os.popen(\"date +'%Y-%m-%d_%H-%M-%S'\").read().strip()\n",
    "\n",
    "with open(f\"log/{date}.log\", \"w\") as f:\n",
    "    f.write(f\"{bs=} {shuffle=} {len(dataset)=}\\n\")\n",
    "    batch_idx = 0\n",
    "\n",
    "    for images, image_ids in tqdm(dataloader):\n",
    "        f.write(f\"{batch_idx=}\\n\")\n",
    "        batch_idx += 1\n",
    "\n",
    "        for class_name in selected_class_names:\n",
    "            f.write(f\"{class_name=}\\n\")\n",
    "            label_name = label_names[class_name]\n",
    "            text_inputs = processor(text=[f\"A photo of a {label}\" for label in label_name], return_tensors=\"pt\", padding=True)\n",
    "            text_inputs = text_inputs.to(device)\n",
    "            images = images.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**text_inputs, pixel_values=images)\n",
    "\n",
    "            logits_per_image = outputs.logits_per_image\n",
    "            probs = logits_per_image.softmax(dim=1)\n",
    "\n",
    "            probs = probs.to(\"cpu\")\n",
    "\n",
    "            values, indices = torch.topk(probs, k=5, dim=1)\n",
    "        \n",
    "            for i, idx in enumerate(indices):\n",
    "                true_label = articles.loc[article_id_to_idx[image_ids[i].item()], class_name]\n",
    "                top5_correct[class_name] += (true_label in [label_name[j.item()] for j in idx])\n",
    "                top1_correct[class_name] += (true_label == label_name[idx[0].item()])\n",
    "\n",
    "    f.write(f\"{top1_correct=}\\n\")\n",
    "    f.write(f\"{top5_correct=}\\n\")\n",
    "\n",
    "for class_name in selected_class_names:\n",
    "    print(f\"{class_name=}\")\n",
    "    print(f\"Top-1 accuracy: {top1_correct[class_name] / len(dataset)}\")\n",
    "    print(f\"Top-5 accuracy: {top5_correct[class_name] / len(dataset)}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
