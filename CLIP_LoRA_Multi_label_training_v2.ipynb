{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":31254,"databundleVersionId":3103714,"sourceType":"competition"},{"sourceId":9588162,"sourceType":"datasetVersion","datasetId":5847476}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom tqdm.notebook import tqdm\nimport os\nfrom pathlib import Path\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom torch.optim import AdamW\nimport torch.nn.functional as F\nimport torch\nimport json \nimport os\nimport wandb\nimport torch\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:07:22.402761Z","iopub.execute_input":"2024-10-10T15:07:22.403060Z","iopub.status.idle":"2024-10-10T15:07:42.119336Z","shell.execute_reply.started":"2024-10-10T15:07:22.403025Z","shell.execute_reply":"2024-10-10T15:07:42.118289Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.13.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.44.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.33.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.4)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.13.1-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.13.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Features table of product items\n\n### This table contains all h&m articles with details such as a type of product, a color, a product group and other features.  \n**Article data description:**\n\n- `article_id` : A unique identifier of every article.\n- `product_code`, `prod_name` : A unique identifier of every product and its name (not the same).\n- `product_type`, `product_type_name` : The group of product_code and its name.\n- `product_group_name` : Product Group. Father to product type.\n- `graphical_appearance_no`, `graphical_appearance_name` : The group of graphics and its name.\n- `colour_group_code`, `colour_group_name` : The group of color and its name.\n- `perceived_colour_value_id`, `perceived_colour_value_name`, `perceived_colour_master_id`, `perceived_colour_master_name` : The added color info.\n- `department_no`, `department_name` : A unique identifier of every department and its name.\n- `index_code`, `index_name` : A unique identifier of every index and its name.\n- `index_group_no`, `index_group_name` : A group of indices and its name.\n- `section_no`, `section_name` : A unique identifier of every section and its name.\n- `garment_group_no`, `garment_group_name` : A unique identifier of every garment and its name.\n- `detail_desc` : Details.","metadata":{}},{"cell_type":"code","source":"text_path = '/kaggle/input/h-and-m-personalized-fashion-recommendations/articles.csv'\narticles = pd.read_csv(text_path)\nprint(articles.shape) # 100k data points\narticles.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:06:58.503557Z","iopub.execute_input":"2024-10-10T08:06:58.503920Z","iopub.status.idle":"2024-10-10T08:06:59.616811Z","shell.execute_reply.started":"2024-10-10T08:06:58.503858Z","shell.execute_reply":"2024-10-10T08:06:59.615752Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(105542, 25)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   article_id  product_code          prod_name  product_type_no  \\\n0   108775015        108775          Strap top              253   \n1   108775044        108775          Strap top              253   \n2   108775051        108775      Strap top (1)              253   \n3   110065001        110065  OP T-shirt (Idro)              306   \n4   110065002        110065  OP T-shirt (Idro)              306   \n\n  product_type_name  product_group_name  graphical_appearance_no  \\\n0          Vest top  Garment Upper body                  1010016   \n1          Vest top  Garment Upper body                  1010016   \n2          Vest top  Garment Upper body                  1010017   \n3               Bra           Underwear                  1010016   \n4               Bra           Underwear                  1010016   \n\n  graphical_appearance_name  colour_group_code colour_group_name  ...  \\\n0                     Solid                  9             Black  ...   \n1                     Solid                 10             White  ...   \n2                    Stripe                 11         Off White  ...   \n3                     Solid                  9             Black  ...   \n4                     Solid                 10             White  ...   \n\n   department_name index_code        index_name index_group_no  \\\n0     Jersey Basic          A        Ladieswear              1   \n1     Jersey Basic          A        Ladieswear              1   \n2     Jersey Basic          A        Ladieswear              1   \n3   Clean Lingerie          B  Lingeries/Tights              1   \n4   Clean Lingerie          B  Lingeries/Tights              1   \n\n   index_group_name section_no            section_name garment_group_no  \\\n0        Ladieswear         16  Womens Everyday Basics             1002   \n1        Ladieswear         16  Womens Everyday Basics             1002   \n2        Ladieswear         16  Womens Everyday Basics             1002   \n3        Ladieswear         61         Womens Lingerie             1017   \n4        Ladieswear         61         Womens Lingerie             1017   \n\n   garment_group_name                                        detail_desc  \n0        Jersey Basic            Jersey top with narrow shoulder straps.  \n1        Jersey Basic            Jersey top with narrow shoulder straps.  \n2        Jersey Basic            Jersey top with narrow shoulder straps.  \n3   Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...  \n4   Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...  \n\n[5 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_id</th>\n      <th>product_code</th>\n      <th>prod_name</th>\n      <th>product_type_no</th>\n      <th>product_type_name</th>\n      <th>product_group_name</th>\n      <th>graphical_appearance_no</th>\n      <th>graphical_appearance_name</th>\n      <th>colour_group_code</th>\n      <th>colour_group_name</th>\n      <th>...</th>\n      <th>department_name</th>\n      <th>index_code</th>\n      <th>index_name</th>\n      <th>index_group_no</th>\n      <th>index_group_name</th>\n      <th>section_no</th>\n      <th>section_name</th>\n      <th>garment_group_no</th>\n      <th>garment_group_name</th>\n      <th>detail_desc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>108775015</td>\n      <td>108775</td>\n      <td>Strap top</td>\n      <td>253</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>9</td>\n      <td>Black</td>\n      <td>...</td>\n      <td>Jersey Basic</td>\n      <td>A</td>\n      <td>Ladieswear</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>16</td>\n      <td>Womens Everyday Basics</td>\n      <td>1002</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>108775044</td>\n      <td>108775</td>\n      <td>Strap top</td>\n      <td>253</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>10</td>\n      <td>White</td>\n      <td>...</td>\n      <td>Jersey Basic</td>\n      <td>A</td>\n      <td>Ladieswear</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>16</td>\n      <td>Womens Everyday Basics</td>\n      <td>1002</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>108775051</td>\n      <td>108775</td>\n      <td>Strap top (1)</td>\n      <td>253</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>1010017</td>\n      <td>Stripe</td>\n      <td>11</td>\n      <td>Off White</td>\n      <td>...</td>\n      <td>Jersey Basic</td>\n      <td>A</td>\n      <td>Ladieswear</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>16</td>\n      <td>Womens Everyday Basics</td>\n      <td>1002</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>110065001</td>\n      <td>110065</td>\n      <td>OP T-shirt (Idro)</td>\n      <td>306</td>\n      <td>Bra</td>\n      <td>Underwear</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>9</td>\n      <td>Black</td>\n      <td>...</td>\n      <td>Clean Lingerie</td>\n      <td>B</td>\n      <td>Lingeries/Tights</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>61</td>\n      <td>Womens Lingerie</td>\n      <td>1017</td>\n      <td>Under-, Nightwear</td>\n      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>110065002</td>\n      <td>110065</td>\n      <td>OP T-shirt (Idro)</td>\n      <td>306</td>\n      <td>Bra</td>\n      <td>Underwear</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>10</td>\n      <td>White</td>\n      <td>...</td>\n      <td>Clean Lingerie</td>\n      <td>B</td>\n      <td>Lingeries/Tights</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>61</td>\n      <td>Womens Lingerie</td>\n      <td>1017</td>\n      <td>Under-, Nightwear</td>\n      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# LoRA finetune CLIP (single column) (ignored)","metadata":{}},{"cell_type":"markdown","source":"## Dataset on product_group_name ","metadata":{}},{"cell_type":"code","source":"# import os\n# import pandas as pd\n# from datasets import Dataset\n# import itertools\n\n# # 图片文本目录路径\n# images_path = '/kaggle/input/h-and-m-personalized-fashion-recommendations/images'\n# text_path = '/kaggle/input/h-and-m-personalized-fashion-recommendations/articles.csv'\n\n# # 读取csv文件\n# # df = pd.read_csv(text_path)\n# df = articles\n# df['image_path'] = ''\n\n# # 为每个article_id添加对应的图片路径，并将表格保存到/kaggle/working/articles_with_image_path.csv\n# for i in range(df.shape[0]):\n#     # 用article_id获取图片路径\n#     article_id = str(df.iloc[i]['article_id'])\n#     image_path = images_path + f'/0{article_id[:2]}' + f'/0{article_id}.jpg'\n#     if not os.path.exists(image_path):\n#         continue\n#     df.loc[i, 'image_path'] = image_path\n    \n\n# df.to_csv('/kaggle/working/articles_with_image_path.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:06:59.618295Z","iopub.execute_input":"2024-10-10T08:06:59.618825Z","iopub.status.idle":"2024-10-10T08:06:59.623896Z","shell.execute_reply.started":"2024-10-10T08:06:59.618773Z","shell.execute_reply":"2024-10-10T08:06:59.622957Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# # remove all the columns that their image_path is NAN\n# df = pd.read_csv('/kaggle/working/articles_with_image_path.csv')\n# filter_product_group_name = ['Unknown','Underwear/nightwear','Cosmetic','Bags','Items',\n#     'Furniture','Garment and Shoe care','Stationery','Interior textile','Fun']\n# format_df = df[df['image_path'].notna() & (df['image_path'] != '') & (~df['product_group_name'].isin(filter_product_group_name))]\n# print(f'清洗后的df行列数: {format_df.shape}')\n\n# # 将df拆分为测试集df和训练集df，并保证product_group_name类别比例保持一致。\n# from sklearn.model_selection import StratifiedShuffleSplit\n# import pandas as pd\n# import numpy as np\n\n# def stratified_split(df, text_column, test_size=0.2, random_state=42):\n#     # 为每个唯一的 text 值分配一个类别标签\n#     df['text_category'] = pd.Categorical(df[text_column]).codes\n    \n#     # 初始化 StratifiedShuffleSplit\n#     splitter = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n    \n#     # 进行分层抽样\n#     for train_index, test_index in splitter.split(df, df['text_category']):\n#         train_df = df.iloc[train_index].copy()\n#         test_df = df.iloc[test_index].copy()\n    \n#     # 删除临时的 'text_category' 列\n#     train_df.drop('text_category', axis=1, inplace=True)\n#     test_df.drop('text_category', axis=1, inplace=True)\n    \n#     return train_df, test_df\n\n# # 进行分层抽样\n# train_df, val_df = stratified_split(format_df, text_column='product_group_name', test_size=0.2)\n\n# print(f\"训练集大小: {len(train_df)}\")\n# print(f\"验证集大小: {len(val_df)}\")\n\n# # 检查每个集合中各类别的比例\n# def check_proportions(df, column):\n#     return df[column].value_counts(normalize=True)\n\n# print(\"\\n训练集中的类别比例:\")\n# print(check_proportions(train_df, 'product_group_name'))\n\n# print(\"\\n验证集中的类别比例:\")\n# print(check_proportions(val_df, 'product_group_name'))\n# # Unknown之后的占比太小（只占了300个dp不到）感觉可以删除，但如何处理这部分的推理","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:06:59.626855Z","iopub.execute_input":"2024-10-10T08:06:59.627223Z","iopub.status.idle":"2024-10-10T08:06:59.638545Z","shell.execute_reply.started":"2024-10-10T08:06:59.627182Z","shell.execute_reply":"2024-10-10T08:06:59.637056Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Multi labels training","metadata":{}},{"cell_type":"markdown","source":"## Model loading and lora config","metadata":{}},{"cell_type":"code","source":"import torch\nfrom datasets import load_dataset\nfrom peft import LoraConfig, get_peft_model\nfrom transformers import (\n    CLIPProcessor, \n    CLIPModel, \n    TrainingArguments, \n    Trainer\n)\n\n# Load CLIP model and processor\n\nmodel_name = \"openai/clip-vit-base-patch32\"\nmodel = CLIPModel.from_pretrained(model_name)\nprocessor = CLIPProcessor.from_pretrained(model_name)\n\n# Configure LoRA\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\", 'k_proj'],\n    lora_dropout=0.05,\n    bias=\"none\",\n#     task_type=\"classification\"\n)\n\npeft_model = get_peft_model(model, lora_config)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\npeft_model.to(device)\nprint(peft_model.print_trainable_parameters())","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:07:51.306384Z","iopub.execute_input":"2024-10-10T15:07:51.307434Z","iopub.status.idle":"2024-10-10T15:08:13.714017Z","shell.execute_reply.started":"2024-10-10T15:07:51.307388Z","shell.execute_reply":"2024-10-10T15:08:13.713046Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bf1c7897f304d719a9d3f6798a7427c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07dfab7cfa7844c0a502db31e8bd61e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95730fd99d194529aa46b372c26ee638"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db601ede76434cecb664857f6ee313ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcab60cc2c4743a8b2b38644bf437d86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e14d9a35e21049d88d8c7627ac75379a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30044cbcaf844a41a069f7ec04f9db5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d825ce0c072d48e39a94df66c5a60f06"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 1,474,560 || all params: 152,751,873 || trainable%: 0.9653\nNone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data processing and Dataset ","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/articles-with-image-path/articles_with_image_path (1).csv')\ndf = df[df['image_path'].notna() & (df['image_path'] != '')]\ntarget_columns = [\"product_group_name\", \"product_type_name\", \"graphical_appearance_name\", \"colour_group_name\", \"perceived_colour_value_name\", \"perceived_colour_master_name\", \"department_name\", \"index_name\", \"index_group_name\", \"section_name\", \"garment_group_name\"]\n# 11 target col\nprint(df.shape)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:08:13.715613Z","iopub.execute_input":"2024-10-10T15:08:13.716231Z","iopub.status.idle":"2024-10-10T15:08:15.016721Z","shell.execute_reply.started":"2024-10-10T15:08:13.716196Z","shell.execute_reply":"2024-10-10T15:08:15.015836Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"(105100, 27)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0  article_id  product_code          prod_name  product_type_no  \\\n0           0   108775015        108775          Strap top              253   \n1           1   108775044        108775          Strap top              253   \n2           2   108775051        108775      Strap top (1)              253   \n3           3   110065001        110065  OP T-shirt (Idro)              306   \n4           4   110065002        110065  OP T-shirt (Idro)              306   \n\n  product_type_name  product_group_name  graphical_appearance_no  \\\n0          Vest top  Garment Upper body                  1010016   \n1          Vest top  Garment Upper body                  1010016   \n2          Vest top  Garment Upper body                  1010017   \n3               Bra           Underwear                  1010016   \n4               Bra           Underwear                  1010016   \n\n  graphical_appearance_name  colour_group_code  ... index_code  \\\n0                     Solid                  9  ...          A   \n1                     Solid                 10  ...          A   \n2                    Stripe                 11  ...          A   \n3                     Solid                  9  ...          B   \n4                     Solid                 10  ...          B   \n\n         index_name index_group_no  index_group_name section_no  \\\n0        Ladieswear              1        Ladieswear         16   \n1        Ladieswear              1        Ladieswear         16   \n2        Ladieswear              1        Ladieswear         16   \n3  Lingeries/Tights              1        Ladieswear         61   \n4  Lingeries/Tights              1        Ladieswear         61   \n\n             section_name garment_group_no garment_group_name  \\\n0  Womens Everyday Basics             1002       Jersey Basic   \n1  Womens Everyday Basics             1002       Jersey Basic   \n2  Womens Everyday Basics             1002       Jersey Basic   \n3         Womens Lingerie             1017  Under-, Nightwear   \n4         Womens Lingerie             1017  Under-, Nightwear   \n\n                                         detail_desc  \\\n0            Jersey top with narrow shoulder straps.   \n1            Jersey top with narrow shoulder straps.   \n2            Jersey top with narrow shoulder straps.   \n3  Microfibre T-shirt bra with underwired, moulde...   \n4  Microfibre T-shirt bra with underwired, moulde...   \n\n                                          image_path  \n0  /kaggle/input/h-and-m-personalized-fashion-rec...  \n1  /kaggle/input/h-and-m-personalized-fashion-rec...  \n2  /kaggle/input/h-and-m-personalized-fashion-rec...  \n3  /kaggle/input/h-and-m-personalized-fashion-rec...  \n4  /kaggle/input/h-and-m-personalized-fashion-rec...  \n\n[5 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>article_id</th>\n      <th>product_code</th>\n      <th>prod_name</th>\n      <th>product_type_no</th>\n      <th>product_type_name</th>\n      <th>product_group_name</th>\n      <th>graphical_appearance_no</th>\n      <th>graphical_appearance_name</th>\n      <th>colour_group_code</th>\n      <th>...</th>\n      <th>index_code</th>\n      <th>index_name</th>\n      <th>index_group_no</th>\n      <th>index_group_name</th>\n      <th>section_no</th>\n      <th>section_name</th>\n      <th>garment_group_no</th>\n      <th>garment_group_name</th>\n      <th>detail_desc</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>108775015</td>\n      <td>108775</td>\n      <td>Strap top</td>\n      <td>253</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>9</td>\n      <td>...</td>\n      <td>A</td>\n      <td>Ladieswear</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>16</td>\n      <td>Womens Everyday Basics</td>\n      <td>1002</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n      <td>/kaggle/input/h-and-m-personalized-fashion-rec...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>108775044</td>\n      <td>108775</td>\n      <td>Strap top</td>\n      <td>253</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>10</td>\n      <td>...</td>\n      <td>A</td>\n      <td>Ladieswear</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>16</td>\n      <td>Womens Everyday Basics</td>\n      <td>1002</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n      <td>/kaggle/input/h-and-m-personalized-fashion-rec...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>108775051</td>\n      <td>108775</td>\n      <td>Strap top (1)</td>\n      <td>253</td>\n      <td>Vest top</td>\n      <td>Garment Upper body</td>\n      <td>1010017</td>\n      <td>Stripe</td>\n      <td>11</td>\n      <td>...</td>\n      <td>A</td>\n      <td>Ladieswear</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>16</td>\n      <td>Womens Everyday Basics</td>\n      <td>1002</td>\n      <td>Jersey Basic</td>\n      <td>Jersey top with narrow shoulder straps.</td>\n      <td>/kaggle/input/h-and-m-personalized-fashion-rec...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>110065001</td>\n      <td>110065</td>\n      <td>OP T-shirt (Idro)</td>\n      <td>306</td>\n      <td>Bra</td>\n      <td>Underwear</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>9</td>\n      <td>...</td>\n      <td>B</td>\n      <td>Lingeries/Tights</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>61</td>\n      <td>Womens Lingerie</td>\n      <td>1017</td>\n      <td>Under-, Nightwear</td>\n      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n      <td>/kaggle/input/h-and-m-personalized-fashion-rec...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>110065002</td>\n      <td>110065</td>\n      <td>OP T-shirt (Idro)</td>\n      <td>306</td>\n      <td>Bra</td>\n      <td>Underwear</td>\n      <td>1010016</td>\n      <td>Solid</td>\n      <td>10</td>\n      <td>...</td>\n      <td>B</td>\n      <td>Lingeries/Tights</td>\n      <td>1</td>\n      <td>Ladieswear</td>\n      <td>61</td>\n      <td>Womens Lingerie</td>\n      <td>1017</td>\n      <td>Under-, Nightwear</td>\n      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n      <td>/kaggle/input/h-and-m-personalized-fashion-rec...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def split_dataset(df, val_ratio=0.2, seed=42):\n    \"\"\"\n    将DataFrame划分为训练集和验证集\n    \n    Args:\n        df: 输入的DataFrame\n        val_ratio: 验证集占比，默认0.2\n        seed: 随机种子，用于复现结果\n        \n    Returns:\n        train_df: 训练集DataFrame\n        val_df: 验证集DataFrame\n    \"\"\"\n    # 设置随机种子\n    np.random.seed(seed)\n    \n    # 获取总行数\n    n_total = len(df)\n    \n    # 计算验证集大小\n    n_val = int(n_total * val_ratio)\n    \n    # 生成随机索引\n    indices = np.random.permutation(n_total)\n    val_indices = indices[:n_val]\n    train_indices = indices[n_val:]\n    \n    # 划分数据集\n    val_df = df.iloc[val_indices].copy().reset_index(drop=True)\n    train_df = df.iloc[train_indices].copy().reset_index(drop=True)\n    \n    print(f\"总数据量: {n_total}\")\n    print(f\"训练集大小: {len(train_df)} ({1-val_ratio:.1%})\")\n    print(f\"验证集大小: {len(val_df)} ({val_ratio:.1%})\")\n    \n    return train_df, val_df\n\ntrain_df, val_df = split_dataset(df, val_ratio=0.2)\n\ncolumns_unique_labels = {}\nfor t_col in target_columns:\n    columns_unique_labels[t_col] = list(df[t_col].unique())\nfor k,v in columns_unique_labels.items():\n    print(f'\\nClass {k} has {len(v)} unique labels:')\n    print(v)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:08:15.018114Z","iopub.execute_input":"2024-10-10T15:08:15.018514Z","iopub.status.idle":"2024-10-10T15:08:15.239169Z","shell.execute_reply.started":"2024-10-10T15:08:15.018467Z","shell.execute_reply":"2024-10-10T15:08:15.237974Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"总数据量: 105100\n训练集大小: 84080 (80.0%)\n验证集大小: 21020 (20.0%)\n\nClass product_group_name has 19 unique labels:\n['Garment Upper body', 'Underwear', 'Socks & Tights', 'Garment Lower body', 'Accessories', 'Items', 'Nightwear', 'Unknown', 'Underwear/nightwear', 'Shoes', 'Swimwear', 'Garment Full body', 'Cosmetic', 'Interior textile', 'Bags', 'Furniture', 'Garment and Shoe care', 'Fun', 'Stationery']\n\nClass product_type_name has 131 unique labels:\n['Vest top', 'Bra', 'Underwear Tights', 'Socks', 'Leggings/Tights', 'Sweater', 'Top', 'Trousers', 'Hair clip', 'Umbrella', 'Pyjama jumpsuit/playsuit', 'Bodysuit', 'Hair string', 'Unknown', 'Hoodie', 'Sleep Bag', 'Hair/alice band', 'Belt', 'Boots', 'Bikini top', 'Swimwear bottom', 'Underwear bottom', 'Swimsuit', 'Skirt', 'T-shirt', 'Dress', 'Hat/beanie', 'Kids Underwear top', 'Shorts', 'Shirt', 'Cap/peaked', 'Pyjama set', 'Sneakers', 'Sunglasses', 'Cardigan', 'Gloves', 'Earring', 'Bag', 'Blazer', 'Other shoe', 'Jumpsuit/Playsuit', 'Sandals', 'Jacket', 'Costumes', 'Robe', 'Scarf', 'Coat', 'Other accessories', 'Polo shirt', 'Slippers', 'Night gown', 'Alice band', 'Straw hat', 'Hat/brim', 'Tailored Waistcoat', 'Ballerinas', 'Tie', 'Necklace', 'Pyjama bottom', 'Felt hat', 'Bracelet', 'Blouse', 'Outdoor overall', 'Watch', 'Underwear body', 'Beanie', 'Giftbox', 'Sleeping sack', 'Dungarees', 'Outdoor trousers', 'Wallet', 'Swimwear set', 'Swimwear top', 'Flat shoe', 'Garment Set', 'Ring', 'Waterbottle', 'Wedge', 'Long John', 'Outdoor Waistcoat', 'Pumps', 'Flip flop', 'Braces', 'Bootie', 'Fine cosmetics', 'Heeled sandals', 'Nipple covers', 'Chem. cosmetics', 'Hair ties', 'Underwear corset', 'Bra extender', 'Underdress', 'Underwear set', 'Sarong', 'Soft Toys', 'Leg warmers', 'Blanket', 'Hairband', 'Tote bag', 'Weekend/Gym bag', 'Cushion', 'Backpack', 'Earrings', 'Bucket hat', 'Flat shoes', 'Heels', 'Cap', 'Shoulder bag', 'Side table', 'Accessories set', 'Headband', 'Baby Bib', 'Keychain', 'Dog Wear', 'Washing bag', 'Sewing kit', 'Cross-body bag', 'Moccasins', 'Towel', 'Wood balls', 'Zipper head', 'Mobile case', 'Pre-walkers', 'Toy', 'Marker pen', 'Bumbag', 'Dog wear', 'Eyeglasses', 'Wireless earphone case', 'Stain remover spray', 'Clothing mist']\n\nClass graphical_appearance_name has 30 unique labels:\n['Solid', 'Stripe', 'All over pattern', 'Melange', 'Transparent', 'Metallic', 'Application/3D', 'Denim', 'Colour blocking', 'Dot', 'Other structure', 'Contrast', 'Treatment', 'Check', 'Chambray', 'Front print', 'Glittering/Metallic', 'Mixed solid/pattern', 'Placement print', 'Other pattern', 'Neps', 'Embroidery', 'Lace', 'Jacquard', 'Unknown', 'Argyle', 'Slub', 'Mesh', 'Sequin', 'Hologram']\n\nClass colour_group_name has 50 unique labels:\n['Black', 'White', 'Off White', 'Light Beige', 'Beige', 'Grey', 'Light Blue', 'Light Grey', 'Dark Blue', 'Dark Grey', 'Pink', 'Dark Red', 'Greyish Beige', 'Light Orange', 'Silver', 'Gold', 'Light Pink', 'Dark Pink', 'Yellowish Brown', 'Blue', 'Light Turquoise', 'Yellow', 'Greenish Khaki', 'Dark Yellow', 'Other Pink', 'Dark Purple', 'Red', 'Transparent', 'Dark Green', 'Other Red', 'Turquoise', 'Dark Orange', 'Other', 'Orange', 'Dark Beige', 'Other Yellow', 'Light Green', 'Other Orange', 'Purple', 'Light Red', 'Light Yellow', 'Green', 'Light Purple', 'Dark Turquoise', 'Bronze/Copper', 'Other Purple', 'Other Turquoise', 'Other Green', 'Other Blue', 'Unknown']\n\nClass perceived_colour_value_name has 8 unique labels:\n['Dark', 'Light', 'Dusty Light', 'Medium Dusty', 'Bright', 'Medium', 'Undefined', 'Unknown']\n\nClass perceived_colour_master_name has 20 unique labels:\n['Black', 'White', 'Beige', 'Grey', 'Blue', 'Pink', 'Lilac Purple', 'Red', 'Mole', 'Orange', 'Metal', 'Brown', 'Turquoise', 'Yellow', 'Khaki green', 'Green', 'undefined', 'Unknown', 'Yellowish Green', 'Bluish Green']\n\nClass department_name has 250 unique labels:\n['Jersey Basic', 'Clean Lingerie', 'Tights basic', 'Baby basics', 'Casual Lingerie', 'Jersey', 'EQ & Special Collections', 'Hair Accessories', 'Other items', 'Baby Nightwear', 'Men Sport Woven', 'Men Sport Bottoms', 'Kids Boy Denim', 'Shopbasket Socks', 'Socks', 'UW', 'Young Girl Jersey Basic', 'Jacket Street', 'Belts', 'Divided Shoes', 'Swimwear', 'Underwear Jersey', 'Basic 1', 'Tops Knitwear DS', 'Men Sport Acc', 'Kids Boy Jersey Basic', 'Young Girl UW/NW', 'Shirt', 'Nightwear', 'Trouser', 'Small Accessories', 'Sunglasses', 'Gloves/Hats', 'Knit & Woven', 'Basics', 'Accessories', 'Jewellery', 'Jersey Fancy DS', 'Trousers DS', 'Bags', 'Blazer S&T', 'Knitwear', 'Woven bottoms', 'Shorts', 'Dresses DS', 'Expressive Lingerie', 'Kids Girl UW/NW', 'Young Boy Jersey Basic', 'Kids Girl S&T', 'Young Girl S&T', 'Shoes / Boots inactive from s5', 'Nursing', 'Jersey Fancy', 'Shoes', 'Functional Lingerie', 'Men Sport Tops', 'Other Accessories', 'Young Boy Trouser', 'Outdoor/Blazers DS', 'Mama Lingerie', 'Socks Bin', 'Denim Other Garments', 'Everyday Waredrobe Denim', 'Trousers', 'Denim Trousers', 'Outdoor/Blazers', 'Young Boy Denim', 'Scarves', 'Dresses', 'Skirts', 'Kids Girl Jersey Basic', 'Baby Socks', 'Trousers & Skirt', 'Young Boy Shirt', 'Kids Girl Big Acc', 'Young Girl Denim', 'Flats', 'Baby Toys/Acc', 'Projects Dresses', 'Denim shorts', 'Jersey inactive from s1', 'Promotion/Other/Offer', 'Bags & Items', 'Small Bags', 'Trouser S&T', 'Shirt S&T', 'Woven Tops', 'Denim trousers', 'Young Girl Knitwear', 'Outwear', 'Knitwear inactive from s1', 'Projects Woven Tops', 'Projects Jersey & Knitwear', 'Denim wardrobe H&M man inactive from S.6', 'Baby Boy Outdoor', 'Premium Quality', 'Woven inactive from s1', 'Tops woven DS', 'Newborn', 'Skirt', 'Jersey License', 'Jewellery Extended', 'Light Basic Jersey', 'Suit Extended inactive from s1', 'Young Boy UW/NW', 'Tops Knitwear', 'Kids Boy Socks', 'Young Boy Socks', 'Outdoor inactive from s1', 'Kids Girl Swimwear', 'Young Girl Swimwear', 'Ladies Sport Bras', 'Ladies Sport Bottoms', 'Jersey fancy', 'Blazer', 'Baby Boy Woven', 'Kids Boy Swimwear', 'Young boy Swimwear', 'Kids Dress-up/Football', 'Sneakers small girl inactive from s2', 'Tops Woven', 'Blouse', 'Shorts DS', 'Boots', 'Kids Boy Big Acc', 'Boys Small Acc & Bags', 'Woven top', 'Young Girl Dresses', 'Knitwear Basic', 'Sneakers', 'Dress', 'Baby Girl Woven', 'Baby Girl Jersey Fancy', 'Jacket Casual', 'Kids Boy UW/NW', 'Kids Girl Jersey Fancy', 'Ladies Sport Acc', 'Baby Exclusive', 'Young Boy Shorts', 'EQ Divided Basics', 'Shorts & Skirts', 'Promotion/ Other /Offer', 'Kids Boy Trouser', 'Tops Fancy Jersey', 'Kids Girl Knitwear', 'Kids Boy Jersey Fancy', 'Heels', 'Woven Premium', 'Blouse & Dress', 'Kids Girl Trouser', 'Kids Girl Dresses', 'Projects Woven Bottoms', 'Conscious Exclusive', 'Shoes Other', 'Kids Girl Outdoor', 'Young Girl Jersey Fancy', 'Young Boy Outdoor', 'Young Girl Outdoor', 'Woven Occasion', 'Kids Boy Outdoor', 'Young Boy Jersey Fancy', 'Kids Boy Shoes', 'Ladies Sport Woven', 'Bottoms Girls', 'Tops Girls', 'Young Girl Big Acc', 'Young Boy Shoes', 'Young Boy Knitwear', 'Suit', 'Kids Girl Shoes', 'Jacket Smart', 'Projects', 'Kids Boy Knitwear', 'Woven bottoms inactive from S.7', 'Jersey/Knitwear Premium', 'Sneakers big girl inactive from s2', 'Suit jacket', 'Kids Boy Shirt', 'Jacket', 'Kids Girl Denim', 'Young Girl Trouser', 'Girls Small Acc/Bags', 'Shirt Extended inactive from s1', 'Tops Boys', 'Baby Girl Knitwear', 'Baby Shoes', 'Jackets', 'Jersey Occasion', 'Young Boy Big Acc', 'Kids Girl License', 'Baby Boy Jersey Fancy', 'Bottoms Boys', 'Local relevance', 'Dress-up Boys', 'Baby Boy Knitwear', 'Equatorial Assortment', 'Loungewear', 'Studio Collection', 'Small Acc. Jewellery & Other', 'Woven', 'Outwear & Blazers', 'Underwear Jersey Fancy inactive from s1', 'Special Collection', 'Take Care External', 'Equatorial', 'Divided+', 'OL Extended Sizes', 'Campaigns', 'Underwear Woven', 'Heavy Basic Jersey', 'EQ H&M Man', 'Young Girl Shoes', 'AK Other', 'Kids Boy Shorts', 'Skirts DS', 'Bottoms', 'Shopbasket Lingerie', 'Kids Boy License', 'Baby Girl Outdoor', 'Promotion / Other / Offer', 'Divided+ inactive from s.1', 'Tops & Bottoms Other', 'Take care', 'Girls Local Relevance', 'AK Dresses & Outdoor', 'Limited Edition', 'AK Tops Jersey & Woven', 'AK Tops Knitwear', 'Divided Swimwear', 'AK Bottoms', 'Girls Projects', 'On Demand', 'Test Ladies', 'Socks Wall', 'Jersey inactive from S.6', 'Boys Local Relevance', 'License', 'Price Items', 'Asia Assortment', 'Accessories Boys', 'Read & React', 'EQ Ladies Denim', 'Small Accessories Extended', 'Baby Boy Local Relevance', 'Kids Girl Exclusive', 'Baby Girl Local Relevance', 'EQ Divided Blue', 'Kids Boy Exclusive', 'Accessories Other', 'Blanks']\n\nClass index_name has 10 unique labels:\n['Ladieswear', 'Lingeries/Tights', 'Baby Sizes 50-98', 'Menswear', 'Ladies Accessories', 'Sport', 'Children Sizes 92-140', 'Divided', 'Children Sizes 134-170', 'Children Accessories, Swimwear']\n\nClass index_group_name has 5 unique labels:\n['Ladieswear', 'Baby/Children', 'Menswear', 'Sport', 'Divided']\n\nClass section_name has 56 unique labels:\n['Womens Everyday Basics', 'Womens Lingerie', 'Womens Nightwear, Socks & Tigh', 'Baby Essentials & Complements', 'Men Underwear', 'Mama', 'Womens Small accessories', 'Men H&M Sport', 'Kids Boy', 'Divided Basics', 'Girls Underwear & Basics', 'Mens Outerwear', 'Womens Big accessories', 'Divided Accessories', 'Womens Swimwear, beachwear', 'Divided Selected', 'Boys Underwear & Basics', 'Contemporary Street', 'Contemporary Casual', 'Men Accessories', 'Men Suits & Tailoring', 'Womens Everyday Collection', 'Men Shoes', 'Young Boy', 'H&M+', 'Divided Collection', 'Ladies Denim', 'Contemporary Smart', 'Womens Trend', 'Kids Outerwear', 'Young Girl', 'Womens Shoes', 'Womens Tailoring', 'Divided Projects', 'Denim Men', 'Men Other', 'Womens Jackets', 'Men Other 2', 'Baby Boy', 'Womens Casual', 'Kids Accessories, Swimwear & D', 'Ladies H&M Sport', 'Kids & Baby Shoes', 'Baby Girl', 'Kids Girl', 'Divided Complements Other', 'Womens Premium', 'Special Collections', 'Kids Sports', 'Men Project', 'Men Edition', 'Collaborations', 'Divided Asia keys', 'EQ Divided', 'Kids Local Relevance', 'Ladies Other']\n\nClass garment_group_name has 21 unique labels:\n['Jersey Basic', 'Under-, Nightwear', 'Socks and Tights', 'Jersey Fancy', 'Accessories', 'Trousers Denim', 'Outdoor', 'Shoes', 'Swimwear', 'Knitwear', 'Shirts', 'Trousers', 'Dressed', 'Shorts', 'Dresses Ladies', 'Skirts', 'Special Offers', 'Blouses', 'Unknown', 'Woven/Jersey/Knitted mix Baby', 'Dresses/Skirts girls']\n","output_type":"stream"}]},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, dataframe, target_columns_list):\n        self.dataframe = dataframe\n        self.t_columns_list = target_columns_list\n        self.prompt = 'The {column} of photo is {label}' # temporary, need to be changed\n            \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, index):\n        row = self.dataframe.iloc[index]\n        image = Image.open(row['image_path'])\n        \n        text_list = []\n        for t_cols in self.t_columns_list:\n            labels = [row[col].strip() for col in t_cols]\n            text = '. '.join([self.prompt.format(column=' '.join(c.split('_')), label=l) for c, l in zip(t_cols, labels)])\n            text_list.append(text)\n        # select the labels from k columns to create the prompt\n        return {\n            'image': image,\n            'text_list': text_list,\n        }\n    \n# Define data collator for training dataset\ndef collate_fn_train(batch):\n#     print(batch)\n#     一个dp包含了len(t_columns_list)个图片\n    texts = []\n    images = []\n    for item in batch:\n        texts.extend(item['text_list'])\n        images.extend([item['image']] * len(item['text_list']))\n    \n    # 处理文本\n    inputs = processor(\n        text=texts,\n        images=images,\n        padding=True,\n        truncation=True,\n        return_tensors=\"pt\",\n    )\n\n    # 合并文本和图像的输入\n    inputs = {\n        'input_ids': inputs['input_ids'],\n        'attention_mask': inputs['attention_mask'],\n        'pixel_values': inputs['pixel_values'],\n    }\n    \n    return inputs\n\n\nfrom torch.utils.data import Dataset, ConcatDataset\n\nt_columns_list = [\n    [\"product_group_name\", \"product_type_name\", \"graphical_appearance_name\"],\n    [\"colour_group_name\", \"perceived_colour_value_name\", \"perceived_colour_master_name\"],\n    [\"department_name\", \"index_name\", \"index_group_name\"],\n    [\"section_name\", \"garment_group_name\"],\n] \n# 重复构造train_ds再连接起来\n# train_ds_list = []\n# for t_cols in t_columns_list:\n#     train_ds = TrainDataset(train_df, t_cols)\n#     train_ds_list.append(train_ds)\n\n# train_ds = ConcatDataset(train_ds_list)\n\ntrain_ds = TrainDataset(train_df, t_columns_list)\nprint(len(train_ds))\nfor i in range(0, 2):\n    print(train_ds[i])","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:08:15.241361Z","iopub.execute_input":"2024-10-10T15:08:15.241736Z","iopub.status.idle":"2024-10-10T15:08:15.284404Z","shell.execute_reply.started":"2024-10-10T15:08:15.241697Z","shell.execute_reply":"2024-10-10T15:08:15.283505Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"84080\n{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1166x1750 at 0x78BC77895DE0>, 'text_list': ['The product group name of photo is Garment Full body. The product type name of photo is Dress. The graphical appearance name of photo is Check', 'The colour group name of photo is Light Purple. The perceived colour value name of photo is Dusty Light. The perceived colour master name of photo is Lilac Purple', 'The department name of photo is Dresses. The index name of photo is Divided. The index group name of photo is Divided', 'The section name of photo is Divided Collection. The garment group name of photo is Dresses Ladies']}\n{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1470x1750 at 0x78BC778958D0>, 'text_list': ['The product group name of photo is Garment Upper body. The product type name of photo is Hoodie. The graphical appearance name of photo is Solid', 'The colour group name of photo is Grey. The perceived colour value name of photo is Dusty Light. The perceived colour master name of photo is Grey', 'The department name of photo is Jersey. The index name of photo is Ladieswear. The index group name of photo is Ladieswear', 'The section name of photo is Womens Casual. The garment group name of photo is Jersey Fancy']}\n","output_type":"stream"}]},{"cell_type":"code","source":"class ValidateDataset(Dataset):\n    def __init__(self, dataframe, target_columns):\n        self.dataframe = dataframe\n        self.target_columns = target_columns\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        row = self.dataframe.iloc[index]\n#         image = Image.open(row['image_path'])\n        dp = [row['image_path']]\n        dp += [row[col] for col in self.target_columns]\n        return dp\n    \nval_ds = ValidateDataset(val_df, target_columns)\nfor i in range(2):\n    print(val_ds[i])","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:08:15.285655Z","iopub.execute_input":"2024-10-10T15:08:15.286023Z","iopub.status.idle":"2024-10-10T15:08:15.294146Z","shell.execute_reply.started":"2024-10-10T15:08:15.285980Z","shell.execute_reply":"2024-10-10T15:08:15.293260Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['/kaggle/input/h-and-m-personalized-fashion-recommendations/images/055/0559129003.jpg', 'Garment Lower body', 'Trousers', 'Denim', 'Blue', 'Medium Dusty', 'Blue', 'Young Boy Denim', 'Children Sizes 134-170', 'Baby/Children', 'Young Boy', 'Trousers Denim']\n['/kaggle/input/h-and-m-personalized-fashion-recommendations/images/050/0500262002.jpg', 'Garment Upper body', 'Blazer', 'Solid', 'Black', 'Dark', 'Black', 'Suit', 'Ladieswear', 'Ladieswear', 'Womens Tailoring', 'Dressed']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Inference","metadata":{"execution":{"iopub.status.busy":"2024-10-08T14:47:58.491238Z","iopub.execute_input":"2024-10-08T14:47:58.492260Z","iopub.status.idle":"2024-10-08T14:47:58.497849Z","shell.execute_reply.started":"2024-10-08T14:47:58.492211Z","shell.execute_reply":"2024-10-08T14:47:58.496508Z"}}},{"cell_type":"code","source":"# 需要推理的目标column name和每个column的unique label\ndef single_column_infer_fn(model, images, column, unique_labels):\n    '''\n    input: \n        model: CLIP model\n        processor: CLIP processor (global).\n        images: path of images\n        column: the specific column name\n        unique_labels: all possible unique labels in this column\n    output: \n        probs: classification probabilities\n    '''\n    infer_prompt = 'The {c} of photo is {label}' # temporary, need to be changed\n    col = ' '.join(column.split('_')) # replaced _ by space\n    unique_prompts = [infer_prompt.format(c=col, label=l) for l in unique_labels]\n    device = model.device\n    images = [Image.open(i) for i in images]\n    \n    inputs = processor(\n        text=unique_prompts,\n        images=images,\n        padding=True,\n        truncation=True,\n        return_tensors=\"pt\",\n    )\n    \n    input_ids = inputs['input_ids'].to(device)\n    attention_mask = inputs['attention_mask'].to(device)\n    pixel_values = inputs['pixel_values'].to(device)\n\n    with torch.no_grad():\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask if attention_mask is not None else None,\n            pixel_values=pixel_values\n        )\n        logits_per_image = outputs.logits_per_image\n    return logits_per_image","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:08:15.295294Z","iopub.execute_input":"2024-10-10T15:08:15.295590Z","iopub.status.idle":"2024-10-10T15:08:15.311199Z","shell.execute_reply.started":"2024-10-10T15:08:15.295557Z","shell.execute_reply":"2024-10-10T15:08:15.310399Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def compute_loss_and_eval(model, val_dl, columns_unique_labels):\n    '''\n    columns_unique_labels: {'column_name1': ['unique_label_name'], 'column_name2': ['unique_label_name']}.\n    val_dl: 'image', 'column1', 'column2' ...\n    '''\n    device = model.device\n    print(f'{len(columns_unique_labels)} column need to be evaluated')\n    \n    all_cols_results = {}\n    column_id = 0\n    for column, unique_labels in columns_unique_labels.items():\n        column_id += 1\n        print(f'\\nEvaluation on column: {column}')\n        all_preds = []\n        all_labels = []\n        single_column_loss = 0\n        for batch in tqdm(val_dl):\n            # batch[0] are batched images\n            logits_per_image = single_column_infer_fn(model, batch[0], column, unique_labels)\n            \n            probs = F.softmax(logits_per_image, dim=-1)\n            preds = [int(idx) for idx in probs.argmax(dim=-1).cpu().numpy()]\n            # batch[1] ~ batch[11] are labels from different columns\n            labels = batch[column_id]\n            # is necessary to compute loss?\n            # 将字符串标签转换为索引\n            label_indices = [unique_labels.index(label) for label in labels]\n            all_labels.extend(label_indices)\n            label_indices = torch.tensor(label_indices, \n                                       device=device)\n            # 计算交叉熵损失\n            loss_fct = torch.nn.CrossEntropyLoss()\n            loss = loss_fct(logits_per_image, label_indices)\n            single_column_loss += loss.item() * len(batch[column_id])\n            all_preds.extend(preds)\n        \n        accuracy = sum(p == l for p, l in zip(all_preds, all_labels)) / len(all_labels)\n        single_column_loss = single_column_loss / len(all_labels)\n        \n        single_col_results = {}\n        single_col_results['accuracy'] = accuracy\n        single_col_results['loss'] = single_column_loss\n        single_col_results['preds'] = all_preds\n        single_col_results['labels'] = all_labels\n        all_cols_results[column] = single_col_results\n        \n        print(f'Model accuracy on {column}: {accuracy}')\n        print(f'Loss on {column}: {single_column_loss}')\n    return all_cols_results\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:08:15.312209Z","iopub.execute_input":"2024-10-10T15:08:15.312669Z","iopub.status.idle":"2024-10-10T15:08:15.324428Z","shell.execute_reply.started":"2024-10-10T15:08:15.312626Z","shell.execute_reply":"2024-10-10T15:08:15.323564Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# # original model evaluation on validate dataset\n# val_dl = DataLoader(val_ds, batch_size=256)\n# tmp = compute_loss_and_eval(model, val_dl, columns_unique_labels)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:28:15.674655Z","iopub.execute_input":"2024-10-10T15:28:15.675100Z","iopub.status.idle":"2024-10-10T15:28:15.701602Z","shell.execute_reply.started":"2024-10-10T15:28:15.675057Z","shell.execute_reply":"2024-10-10T15:28:15.700426Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def save_dict_to_json(dictionary, filepath, indent=4, ensure_ascii=False):\n    \"\"\"\n    将字典保存为JSON文件\n    \n    Args:\n        dictionary: 要保存的字典\n        filepath: 保存路径\n        indent: 缩进空格数\n        ensure_ascii: 是否确保ASCII编码（False则支持中文）\n    \"\"\"\n    # 确保目录存在\n    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n    \n    # 保存为JSON\n    with open(filepath, 'w', encoding='utf-8') as f:\n        json.dump(dictionary, f, indent=indent, ensure_ascii=ensure_ascii)\n\n# tmp = {'1':{'loss':1, 'acc':1, 'preds':[1,2,3,4]}, '666':{'loss':1, 'acc':1, 'labels':[1,2,3,4]}, '2':{'loss':1, 'acc':1, 'preds':[1,2,3,4], 'labels':[1,2,3,4]}}\n# save_dict_to_json(tmp, '/kaggle/working/epoch0.json')","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:08:17.854343Z","iopub.execute_input":"2024-10-10T15:08:17.855351Z","iopub.status.idle":"2024-10-10T15:08:17.862173Z","shell.execute_reply.started":"2024-10-10T15:08:17.855308Z","shell.execute_reply":"2024-10-10T15:08:17.861245Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Training loop func","metadata":{}},{"cell_type":"code","source":"def save_clip_checkpoint(model, optimizer, epoch, loss, config=None, save_dir='checkpoints'):\n    \"\"\"\n    保存CLIP模型检查点\n    \n    Args:\n        model: CLIP模型\n        optimizer: 优化器\n        epoch: 当前轮次\n        loss: 当前loss\n        config: 训练配置\n        save_dir: 保存目录\n    \"\"\"\n    # 创建保存目录\n    os.makedirs(save_dir, exist_ok=True)\n    \n    # 生成文件名，包含时间戳和epoch信息\n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    filename = f'clip_checkpoint_epoch{epoch}_{timestamp}.pth'\n    filepath = os.path.join(save_dir, filename)\n    \n    # 准备要保存的数据\n    checkpoint = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': loss,\n        'config': config,\n        'timestamp': timestamp\n    }\n    \n    # 保存模型\n    torch.save(checkpoint, filepath)\n    \n    # 保存配置信息为单独的JSON文件（便于查看）\n    config_file = os.path.join(save_dir, f'config_epoch{epoch}_{timestamp}.json')\n    with open(config_file, 'w', encoding='utf-8') as f:\n        json.dump(config, f, indent=4, ensure_ascii=False)\n    \n    print(f\"Checkpoint saved: {filepath}\")\n    return filepath\n\ndef train(\n    model=None, \n    train_ds=None, \n    val_ds=None, \n    n_epochs=3, \n    batch_size=128, \n    lr=1e-5, \n    infer_fn=None,\n    project_name=\"H&M\",  # wandb project name\n    run_name='10.09',  # optional wandb run name\n):\n    # Initialize wandb\n    wandb.init(\n        project=project_name,\n        name=run_name,\n        config={\n            \"learning_rate\": lr,\n            \"epochs\": n_epochs,\n            \"batch_size\": batch_size\n        }\n    )\n\n    train_dl = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn_train, shuffle=True)\n    val_dl = DataLoader(val_ds, batch_size=batch_size)\n    optimizer = AdamW(model.parameters(), lr=lr)\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    \n    global_step = 0\n    print('Training Begin...')\n    # 中间结果需要保存到output中\n    for epoch in range(n_epochs):\n        model.train()\n        running_loss = 0.0    \n        for batch in tqdm(train_dl):\n            input_ids = batch['input_ids'].to(device)\n            pixel_values = batch['pixel_values'].to(device)\n            \n            outputs = model(input_ids=input_ids, pixel_values=pixel_values)\n            logits_per_image = outputs.logits_per_image\n            logits_per_text = outputs.logits_per_text\n            \n            labels = torch.arange(logits_per_image.size(0)).to(device)\n            loss_img = F.cross_entropy(logits_per_image, labels)\n            loss_txt = F.cross_entropy(logits_per_text, labels)\n            loss = (loss_img + loss_txt) / 2\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            global_step += 1\n\n            # Log training loss every 100 steps\n            if global_step % 10 == 0:\n                wandb.log({\n                    \"train/loss\": running_loss / 10,\n                    \"train/step\": global_step\n                })\n                running_loss = 0.0\n        \n        # save model checkpoints\n        save_clip_checkpoint(model, optimizer, epoch, loss)\n        \n        model.eval()\n        \n        # evaluations on all columns take about 2.5 hours, if you don't want to evaluate, comment it\n        all_cols_res = compute_loss_and_eval(model, val_dl, columns_unique_labels)\n        save_dict_to_json(all_cols_res, f'/kaggle/working/epoch-{epoch + 1}.json')\n        # Log validation metrics\n        log_dict = {\n            f\"val/epoch\": epoch,\n        }\n        \n        # Log individual column metrics\n        for column, d in all_cols_res.items():\n            log_dict.update({\n                f\"val/loss_{column}\": d['loss'],\n                f\"val/accuracy_{column}\": d['accuracy']\n            })\n        \n        wandb.log(log_dict)\n        \n        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n        print(f\"Evaluation results on val_dl:\\n {acc_loss_dict}\")\n    \n    # Close wandb run\n    wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:21:10.385303Z","iopub.execute_input":"2024-10-10T15:21:10.386184Z","iopub.status.idle":"2024-10-10T15:21:10.409530Z","shell.execute_reply.started":"2024-10-10T15:21:10.386139Z","shell.execute_reply":"2024-10-10T15:21:10.408658Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Ready to Train","metadata":{}},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:21:11.864353Z","iopub.execute_input":"2024-10-10T15:21:11.865108Z","iopub.status.idle":"2024-10-10T15:21:12.782450Z","shell.execute_reply.started":"2024-10-10T15:21:11.865067Z","shell.execute_reply":"2024-10-10T15:21:12.781338Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"train_arg = {\n    'model': peft_model,\n    'train_ds': train_ds,\n    'val_ds': val_ds,\n    'n_epochs': 3,\n    'batch_size': 64,\n    'lr': 2e-5,\n    'infer_fn': None,\n    'run_name': 'test',\n}\nwandb.login(key='2b1626edceae9b68a67d66923587da64398da02c')\ntrain(**train_arg)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T15:21:12.784636Z","iopub.execute_input":"2024-10-10T15:21:12.785090Z","iopub.status.idle":"2024-10-10T15:22:31.245837Z","shell.execute_reply.started":"2024-10-10T15:21:12.785035Z","shell.execute_reply":"2024-10-10T15:22:31.244580Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:jj12dom2) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a70db29b5504c53aa82c8c78a4e5a4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">test</strong> at: <a href='https://wandb.ai/yhanmowsnoo-royal-institute-of-technology/H%26M/runs/jj12dom2' target=\"_blank\">https://wandb.ai/yhanmowsnoo-royal-institute-of-technology/H%26M/runs/jj12dom2</a><br/> View project at: <a href='https://wandb.ai/yhanmowsnoo-royal-institute-of-technology/H%26M' target=\"_blank\">https://wandb.ai/yhanmowsnoo-royal-institute-of-technology/H%26M</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241010_152021-jj12dom2/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:jj12dom2). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.18.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241010_152112-ke4dxloe</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/yhanmowsnoo-royal-institute-of-technology/H%26M/runs/ke4dxloe' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/yhanmowsnoo-royal-institute-of-technology/H%26M' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/yhanmowsnoo-royal-institute-of-technology/H%26M' target=\"_blank\">https://wandb.ai/yhanmowsnoo-royal-institute-of-technology/H%26M</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/yhanmowsnoo-royal-institute-of-technology/H%26M/runs/ke4dxloe' target=\"_blank\">https://wandb.ai/yhanmowsnoo-royal-institute-of-technology/H%26M/runs/ke4dxloe</a>"},"metadata":{}},{"name":"stdout","text":"Training Begin...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1314 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c4773c0119e4b7fb920f92f83e68c9e"}},"metadata":{}},{"name":"stdout","text":"Checkpoint saved: checkpoints/clip_checkpoint_epoch0_20241010_152143.pth\n","output_type":"stream"},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}